ğŸ§  Prodigy ML Task 1-House price prediction using Regression models
This repository contains the solution for Task 1 of the Prodigy Machine Learning internship/assessment. The notebook demonstrates data preprocessing, model training, evaluation, and insights for a classification/regression problem using popular ML libraries.
ğŸ“¦prodigy_ML_task1/
 â”£ ğŸ“œ prodigy_ML_task1.ipynb
 â”— ğŸ“œ README.md
âœ… Features
Data loading and exploration

Data cleaning and preprocessing

Feature selection/engineering

Model selection and training (e.g., Logistic Regression, Random Forest, etc.)

Model evaluation using metrics such as accuracy, F1-score, confusion matrix

Visualizations to support analysis

Dataset : - https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data

ğŸ§  Prodigy ML Task 2-K-means clustering algorithm to group customers of a retail store based on their purchase history.
Dataset :- https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python

ğŸ§  Prodigy ML Task 3-classification of cats and dogs using svm
Dataset :- https://www.kaggle.com/c/dogs-vs-cats/data
Description: The dataset contains 25,000 images of dogs and cats labeled as dog or cat.
# ğŸ¶ğŸ± Cat vs Dog Image Classification using SVM

## ğŸ“‚ Overview

This project performs binary image classification to distinguish between images of **cats and dogs** using a **Support Vector Machine (SVM)** model. The entire pipelineâ€”from data preprocessing to training and evaluationâ€”is implemented in the Jupyter notebook `prodigy_ml_task3.ipynb`.

---

## ğŸ“ Files

- `prodigy_ml_task3.ipynb`: Contains the complete code for preprocessing the dataset, training the SVM model, and evaluating its performance.

---

## ğŸ§° Libraries Used

The following Python libraries are used in this project:

- `numpy` â€“ for numerical operations
- `pandas` â€“ for data handling
- `matplotlib`, `seaborn` â€“ for data visualization
- `sklearn` â€“ for SVM, preprocessing, splitting, and evaluation
- `cv2` (OpenCV) â€“ for image loading and processing

Install all dependencies with:

```bash
pip install -r requirements.txt




