## 🧠 Prodigy ML Task 1-House price prediction using Regression models
This repository contains the solution for Task 1 of the Prodigy Machine Learning internship/assessment. The notebook demonstrates data preprocessing, model training, evaluation, and insights for a classification/regression problem using popular ML libraries.
📦prodigy_ML_task1/
 ┣ 📜 prodigy_ML_task1.ipynb
 ┗ 📜 README.md
✅ Features
Data loading and exploration

Data cleaning and preprocessing

Feature selection/engineering

Model selection and training (e.g., Logistic Regression, Random Forest, etc.)

Model evaluation using metrics such as accuracy, F1-score, confusion matrix

Visualizations to support analysis

Dataset : - https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data

## 🧠 Prodigy ML Task 2-K-means clustering algorithm to group customers of a retail store based on their purchase history.
Dataset :- https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python
## 📂 Overview

This project applies **unsupervised machine learning techniques**—K-Means and Hierarchical Clustering—to segment retail store customers based on their **purchase history** and **spending patterns**. The goal is to identify customer groups for **targeted marketing**, **loyalty programs**, and **business strategy optimization**.


## 🧠 Prodigy ML Task 3-classification of cats and dogs using svm
Dataset :- https://www.kaggle.com/c/dogs-vs-cats/data
Description: The dataset contains 25,000 images of dogs and cats labeled as dog or cat.
# 🐶🐱 Cat vs Dog Image Classification using SVM

## 📂 Overview

This project performs binary image classification to distinguish between images of **cats and dogs** using a **Support Vector Machine (SVM)** model. The entire pipeline—from data preprocessing to training and evaluation—is implemented in the Jupyter notebook `prodigy_ml_task3.ipynb`.

---

## 📁 Files

- `prodigy_ml_task3.ipynb`: Contains the complete code for preprocessing the dataset, training the SVM model, and evaluating its performance.
-`task_3_model_predictions.docx` : contains teh output of dog and cat model predictions
---

## 🧰 Libraries Used

The following Python libraries are used in this project:

- `numpy` – for numerical operations
- `pandas` – for data handling
- `matplotlib`, `seaborn` – for data visualization
- `sklearn` – for SVM, preprocessing, splitting, and evaluation
- `cv2` (OpenCV) – for image loading and processing

Install all dependencies with:

```bash
pip install -r requirements.txt

```
## 🧠 Prodigy ML Task 4: ✋ Develop a hand gesture recognition model that can accurately identify and classify different hand gestures from image or video data, enabling intuitive human-computer interaction and gesture-based control systems

## 📂 Overview

This project focuses on developing a **Convolutional Neural Network (CNN)** model to accurately recognize and classify different **hand gestures** from images. It enables intuitive **human-computer interaction** and can serve as a foundational model for **gesture-based control systems**.

The model achieves an impressive **accuracy of 97.97%** on the test data, showing high potential for real-world applications such as virtual input systems, sign language translation, and touchless control interfaces.
Dataset :-  https://www.kaggle.com/gti-upm/leapgestrecog
Description: Contains 20000+ grayscale images (128x128 pixels) of 10 different hand gestures collected from 10 users.
---

## 📁 Files

- `prodigy_ml_task4.ipynb` – Main Jupyter Notebook containing the complete model pipeline, including data loading, CNN model building, training, evaluation, and visualization.
- `README.md` – Project documentation and usage guide.

---

## 🧰 Libraries Used

- `numpy` – for numerical operations  
- `pandas` – for data handling  
- `matplotlib`, `seaborn` – for plotting graphs and results  
- `tensorflow` / `keras` – for building and training the CNN  
- `scikit-learn` – for model evaluation metrics and data splitting  
- `OpenCV` (optional) – for video or image processing if extended to real-time

To install all required packages, run:

```bash
pip install -r requirements.txt
```




